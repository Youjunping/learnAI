{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一.关联规则的支持度/置信度/提升度\n",
    "\n",
    "1.支持度\n",
    "某商品或商品组合在总交易中出现次数的比率,也就是百分比;用support表示\n",
    "支持度越高,该商品(或组合)出现的频率就越大;支持度高的商品,简单理解,就是常购商品,比如超市的米/面/油/蔬菜/牛奶/面包/啤酒/尿布等\n",
    "\n",
    "支持度的计算很简单,就是将商品在购物篮(订单)的次数除以购物的次数总和,以一个购物小票计算为一次,里面会有多件商品.\n",
    "\n",
    "2.置信度\n",
    "一个条件概率,是指购买了商品A(或商品组合A)的交易里,B出现的频率;可以理解为两者A/B同时出现的概率除以A单独出现的概率,用confidence(A=>B)表示\n",
    "\n",
    "置信度的计算,confidence(A => B): P(A,B)/P(A); confidence(B => A): P(A,B)/P(B).\n",
    "可以看出两者不相等\n",
    "\n",
    "3.提升度\n",
    "是指商品A(或组合A)的出现,对商品B的销售带来的提升倍数;实际业务场景中,可以理解为促销商品对其它商品的销售带动;\n",
    "\n",
    "提升度的计算需要两个维度:一个是confidence(A => B),及购买A以后,购买B的条件概率 ; 另外一个维度,是单独购买B的概率;提升度两者相除;\n",
    "即如下:提升度(A => B):confidence(A => B)/support(B)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二.关联规则与协同过滤的区别\n",
    "\n",
    "1.对象不同\n",
    "关联规则,研究的对象是交易的物品,是众多客户的购买物品统计; 协同过滤,研究的是用户,准确的说是某一个具体的用户;\n",
    "\n",
    "2.内容不同\n",
    "关联规则,是针对购物篮进行分析; 协同过滤,是基于相似度进行分析,对用户的偏好进行归类/评分\n",
    "\n",
    "3.应用场景不同\n",
    "关联规则,用于分析物品的销售排序及物品之间的联系,是基于一段较长时间的记录(历史数据),可以用于冷启动; 协同过滤, 更多的是基于当下的行为(动态数据)进行个性化推荐,更实时/精准;\n",
    "\n",
    "4.结果不同\n",
    "关联规则,是挖掘商品之间的关联,从而提升整体的销量; 协同过滤,是千人千面,进行内容或商品的个性化推荐,提高单个用户的体验/粘性,或是提升销量;\n",
    "\n",
    "5.思想不同\n",
    "关联规则,着眼于物品,眼里没有具体的客户,是粗放式的思考;协同过滤,着眼于客户,是精细化运营,应用领域更宽泛,可以是动态的商品,也可以是不产生交易的服务,盈利模式可以是广告分发,也可以是直播带货.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三.为什么需要多种推荐算法\n",
    "\n",
    "1.不同的场景 需求不同 \n",
    "线上线下,满足的需求不同;有数据和无数据,推荐算法不同;有历史的交易数据和最新的客户行为数据的,算法也不同;基于静态的内容(或物品)属性,与基于动态的行为数据不同,推荐方式也不同\n",
    "\n",
    "2.不同的算法,成本不同\n",
    "低维度/复杂度的数据,算法简单,成本低;而高维度/复杂度的数据,对算力要求高,成本也高;\n",
    "\n",
    "3.每种算法都有其优势,也有劣势\n",
    "经典的算法,如逻辑回归,成熟,应用广泛,有效性高,但准确度有极限,要再提高很难;\n",
    "传统的算法,在解决复杂的人机交互对话时,就难以做到简单/高效,因为语言/用词是不断变化的,不断地有新的流行用语被创造出来,就需要机器能自我学习;\n",
    "\n",
    "4.数据结构不同\n",
    "有标签/无标签,能采用的算法不同;人工标注跟无监督学习,算法也不同;另外,数据是否齐全/完整,也会影响算法的选择.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四.关联规则参数的设定\n",
    "\n",
    "\n",
    "1.最小支持度\n",
    "\n",
    "通过test不同的设置,观察结果,获得适合的min_support\n",
    "\n",
    "不同的数据集,其大小会影响合理的最小支持度,数据集越大,min_support应设的小一些,从0.01-0.5在数据集不大的情况下,通常是合理的;\n",
    "也可以对支持度排序,从高到低取前20个物品(或组合)的支持度,作为选取的参考;\n",
    "\n",
    "2.最小置信度\n",
    "确定方法跟最小支持度类似,只是取值范围会往大的方向调整,通常为0.1-1之间.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 五.常见的回归分析方法及评价指标\n",
    "\n",
    "1.线性回归\n",
    "\n",
    "假定自变量与因变量之间存在线性关系,用于连续值的预测,即回归问题 \n",
    "目标是找到预测Y 的线性方程  Y_hat = w^T * X + b\n",
    "评价指标用 Loss = (Y_i - Y_hati)**2 最小 \n",
    "或 loss = Y_i - Y_hati 的绝对值最小\n",
    "\n",
    "2.逻辑回归\n",
    "\n",
    "用于确定事件的发生概率,常用Logistic函数(Sigmoid)表示事件的概率,用于分类问题\n",
    "使用方法:结合线性回归,将线性回归的预测值Y作为Sigmoid函数的输入值,代入到Sigmoid函数,得到落入0-1区间的事件概率\n",
    "评价指标与线性回归相同\n",
    "\n",
    "3.多项式回归\n",
    "\n",
    "自变量与因变量之间不是线性关系,而是曲线关系,用于回归问题\n",
    "目标预测方程 Y = a + b * X ** 2, 自变量的指数存在>1 的项\n",
    "\n",
    "评价指标与线性回归相同\n",
    "\n",
    "4.正则化\n",
    "\n",
    "在模型太复杂时,为防止过拟合,增加一个惩罚项到损失函数中,用于模型评价\n",
    "正则化项,有L1和L2两种\n",
    "\n",
    "评价指标: 线性回归的损失函数 + 正则化项"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
